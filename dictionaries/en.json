{
    "header": {
        "links": {
            "visionRanking": "Vision Ranking",
            "llmRanking": "LLM Ranking",
            "about": "About"
        }
    },
    "darkModeToggle": {
        "system": "System",
        "light": "Light",
        "dark": "Dark"
    },
    "languageToggle": {
        "english": "English",
        "portuguese": "Portuguese"
    },
    "visionRanking": {
        "title": "Vision Model Ranking",
        "description": "This ranking classifies Android smartphones based on the data collected by the Speed.AI app, which benchmarks AI models natively on Android devices.",
        "help": {
            "label": "Help",
            "content": [
                {
                    "value": "result",
                    "label": "How are the ranking values calculated?",
                    "content": "The ranking values are represented in milliseconds and are obtained through a weighted average that takes into account the number of images used for each test execution. Only inferences that meet the criteria represented in the filter are considered."
                }
            ]
        },
        "filters": {
            "title": "My Filters",
            "subtitle": "Select models and quantizations to be used for calculating the results",
            "models": {
                "label": "Models",
                "types": {
                    "classification": "Classification",
                    "detection": "Detection",
                    "segmentation": "Segmentation",
                    "language": "Language",
                    "other": "Other"
                }
            },
            "quantizations": "Quantizations",
            "toggles": {
                "inferenceNumber": "Show number of inferences",
                "showPowerAndEnergy": "Show power and energy consumed",
                "orderByPowerAndEnergy": "Order by power and energy",
                "removeAll": "Remove all",
                "selectAll": "Select all"
            },
            "buttons": {
                "apply": "Apply filter"
            },
            "warnings": {
                "changesNotSaved": "Changes not saved"
            }
        },
        "alert": {
            "label": "Alert",
            "notSupported": "Models not supported"
        },
        "table": {
            "inference": {
                "singular": "inference",
                "plural": "inferences"
            },
            "unavailable": {
                "inferencesNumber": "Inferences not calculated",
                "powerAndEnergy": "Consumption not calculated"
            }
        }
    },
    "llmRanking": {
        "title": "LLM Ranking",
        "description": "This ranking classifies Android smartphones based on data collected by the Speed.AI LLM Version app, which benchmarks LLMs (Large Language Models, such as Llama and Gemma) on Android devices, using the MLC LLM platform to run the models.",
        "filters": {
            "title": "My Filters",
            "subtitle": "Select models and quantizations to be used for calculating the results",
            "mode": {
                "total": "Total",
                "prefill": "Prefill",
                "decode": "Decode"
            },
            "toggles": {
                "conversationNumber": "Show number of conversations",
                "showPowerAndEnergy": "Show power and energy consumed",
                "orderByPowerAndEnergy": "Order by power and energy"
            },
            "models": {
                "label": "Models"
            }
        },
        "help": {
            "label": "Help",
            "content": [
                {
                    "value": "prefill",
                    "label": "What is prefill?",
                    "content": "Prefill tok/s measures how many tokens the model can process per second during the initial setup phase."
                },
                {
                    "value": "decode",
                    "label": "What is decode?",
                    "content": "Decode tok/s measures how many tokens the model can generate per second during the decoding phase."
                },
                {
                    "value": "conversation",
                    "label": "What is a conversation?",
                    "content": "A conversation is the primary step in benchmarking, during which a predetermined set of questions is posed to the LLM model. Throughout this process, we measure the data used to construct the ranking."
                },
                {
                    "value": "result",
                    "label": "How are tokens per second calculated?",
                    "content": "Tokens per second are calculated using a simple average of all conversations."
                }
            ]
        },
        "phoneAlert": "It is possible that the smartphone names in the ranking are not their commercial names",
        "table": {
            "columns": {
                "result": {
                    "header": "Result"
                }
            },
            "conversation": {
                "singular": "conversation",
                "plural": "conversations"
            },
            "unavailable": {
                "conversatiosnNumber": "Number of conversations not calculated",
                "powerAndEnergy": "Consumption not calculated"
            }
        }
    },
    "about": {
        "aboutLuxAI": {
            "title": "About Lux.AI",
            "content": "Lux.AI is a project developed at the Center for Informatics at UFPE, as part of the PPI (Priority Programs and Projects of the IT Law), with support from the Ministry of Science, Technology, Innovations, and Communications, through the IT Law (Law No. 8.248/91) and the SOFTEX Program.\n\nLux.AIâ€™s main areas of study and development include:\n\n1. Computational Photography\n2. Artificial Intelligence\n3. Image Quality Analysis\n4. Performance Analysis of Heterogeneous Systems.\n\nLux.AI develops mobile applications with AI-based functionalities and applies techniques such as training, fine-tuning, pruning, and other performance optimization methods for AI models.\n\nAdditionally, it offers consulting and personalized services to the industry, covering everything from AI model training and fine-tuning to performance improvement on restrictive hardware."
        }
    }
}