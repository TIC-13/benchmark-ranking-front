{
    "header": {
        "links": {
            "visionRanking": "Ranking de visão",
            "llmRanking": "Ranking de LLMs",
            "about": "Sobre"
        }
    },
    "darkModeToggle": {
        "system": "Sistema",
        "light": "Claro",
        "dark": "Escuro"
    },
    "languageToggle": {
        "english": "Inglês",
        "portuguese": "Português"
    },
    "visionRanking": {
        "title": "Ranking de modelos de visão",
        "help": {
            "label": "Ajuda",
            "content": [
                {
                    "value": "result",
                    "label": "Como os valores do ranking são calculados?",
                    "content": "Os valores do ranking são representados em milissegundos, sendo obtidos por meio de uma média ponderada que leva em conta o número de imagens usados para a execução de cada teste. Apenas inferências que cumprem os critérios representados no filtro são consideradas."
                }
            ]
        },
        "filters": {
            "title": "Meus filtros",
            "subtitle": "Selecione modelos e quantizações que serão usados para calcular os resultados",
            "models": {
                "label": "Modelos",
                "types": {
                    "classification": "Classificação",
                    "detection": "Detecção",
                    "segmentation": "Segmentação",
                    "language": "Linguagem",
                    "other": "Outros"
                }
            },
            "quantizations": "Quantizações",
            "toggles": {
                "inferenceNumber": "Mostrar número de inferências",
                "showPowerAndEnergy": "Mostrar potência e energia consumida",
                "orderByPowerAndEnergy": "Ordenar por potência e energia",
                "removeAll": "Remover todos",
                "selectAll": "Selecionar todos"
            },
            "buttons": {
                "apply": "Aplicar filtro"
            },
            "warnings": {
                "changesNotSaved": "Mudanças não salvas"
            }
        },
        "alert": {
            "label": "Alerta",
            "notSupported": "Modelos não suportados"
        },
        "table": {
            "inference": {
                "singular": "inferência",
                "plural": "inferências"
            },
            "unavailable": {
                "inferencesNumber": "Inferências não calculadas",
                "powerAndEnergy": "Consumo não calculado"
            }
        }
    },
    "llmRanking": {
        "title": "Ranking de LLMs",
        "description": "Ranking de desempenho de LLMs.\nCompara o desempenho de LLMs por celular usando valores de tokens por segundo para realizar as tarefas de prefill e decode",
        "filters": {
            "title": "Meus filtros",
            "subtitle": "Selecione modelos e quantizações que serão usados para calcular os resultados",
            "mode": {
                "total": "Total",
                "prefill": "Prefill",
                "decode": "Decode"
            },
            "toggles": {
                "conversationNumber": "Mostrar número de conversas",
                "showPowerAndEnergy": "Mostrar potência e energia consumida",
                "orderByPowerAndEnergy": "Ordenar por potência e energia"
            },
            "models": {
                "label": "Modelos"
            }
        },
        "help": {
            "label": "Ajuda",
            "content": [
                {
                    "value": "prefill",
                    "label": "O que é prefill?",
                    "content": "Prefill tok/s mede quantos tokens o modelo pode processar por segundo durante a fase inicial de configuração."
                },
                {
                    "value": "decode",
                    "label": "O que é decode?",
                    "content": "Decode tok/s mede quantos tokens o modelo pode gerar por segundo durante a fase de decodificação."
                },
                {
                    "value": "conversation",
                    "label": "O que é uma conversa?",
                    "content": "Uma conversa é a etapa principal na avaliação de desempenho, durante a qual um conjunto predefinido de perguntas é feito ao modelo LLM. Durante esse processo, medimos os dados usados para construir a classificação."
                },
                {
                    "value": "result",
                    "label": "Como os tokens por segundo são calculados?",
                    "content": "Os tokens por segundo são calculados por meio de uma média simples de todas as conversas."
                }
            ]
        },
        "phoneAlert": "É possivel que os nomes dos smartphones no ranking não sejam seus nomes comerciais",     
        "table": {
            "columns": {
                "result": {
                    "header": "Resultado"
                }
            },
            "conversation": {
                "singular": "conversa",
                "plural": "conversas"
            },
            "unavailable": {
                "conversatiosnNumber": "Nº de conversas não calculado",
                "powerAndEnergy": "Consumo não calculado"
            }
        }
    },
    "about": {
        "aboutLuxAI": {
            "title": "Sobre a Lux.AI",
            "content": "Lux.AI é um projeto desenvolvido no Centro de Informática da UFPE, como parte do PPI (Programas e Projetos Prioritários da Lei de Informática), com apoio do Ministério da Ciência, Tecnologia, Inovações e Comunicações, por meio da Lei de Informática (Lei Nº 8.248/91) e do Programa SOFTEX.\n\nAs principais áreas de estudo e desenvolvimento da Lux.AI incluem:\n\n1. Fotografia Computacional\n2. Inteligência Artificial\n3. Análise de Qualidade de Imagem\n4. Análise de Desempenho de Sistemas Heterogêneos.\n\nA Lux.AI desenvolve aplicativos móveis com funcionalidades baseadas em IA e aplica técnicas como treinamento, fine-tuning, pruning e outros métodos de otimização de desempenho para modelos de IA.\n\nAlém disso, oferece consultoria e serviços personalizados para a indústria, abrangendo desde o treinamento e fine-tuning de modelos de IA até a melhoria de desempenho em hardware restritivo."
        }
    }
}