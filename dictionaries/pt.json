{
    "header": {
        "links": {
            "visionRanking": "Ranking de visão",
            "llmRanking": "Ranking de LLMs",
            "about": "Sobre"
        }
    },
    "darkModeToggle": {
        "system": "Sistema",
        "light": "Claro",
        "dark": "Escuro"
    },
    "languageToggle": {
        "english": "Inglês",
        "portuguese": "Português"
    },
    "tableControls": {
        "previous": "Anterior",
        "next": "Próximo"
    },
    "generalWarnings": {
        "atLeastOneSelected": "Pelo menos um valor deve ser selecionado"
    },
    "actions": {
        "runningOn": "Executando na"
    },
    "visionRanking": {
        "title": "Ranking de modelos de visão",
        "appCard": {
            "title": "Speed.AI - AI Benchmarking",
            "description": "App usado para classificar os smartphones. Disponível na PlayStore e no GitHub."
        },
        "description": "Esse ranking classifica smartphones Android pelos valores coletados no aplicativo Speed.AI, que faz benchmarking de modelos de inteligência artificial nativamente em aparelhos Android.",
        "help": {
            "label": "Ajuda",
            "content": [
                {
                    "value": "result",
                    "label": "Como os valores do ranking são calculados?",
                    "content": "Os valores do ranking são representados em milissegundos, sendo obtidos por meio de uma média ponderada que leva em conta o número de imagens usados para a execução de cada teste. Apenas inferências que cumprem os critérios representados no filtro são consideradas."
                }, 
                {
                    "value": "gpu",
                    "label": "Por que o consumo de GPU não está aparecendo?",
                    "content": "Alguns modelos de celulares não possibilitam a coleta da estatística do uso da GPU, por esse motivo alguns valores dessa medida podem estar ausentes."
                }
            ]
        },
        "filters": {
            "title": "Configurações do ranking",
            "subtitle": "Selecione modelos e quantizações que serão usados para calcular os resultados",
            "categories": {
                "speed": "Tempo de inferência (ms)",
                "cpu": "Uso de CPU (%)",
                "gpu": "Uso de GPU (%)",
                "ram": "Uso de RAM (MB)"
            },
            "models": {
                "label": "Modelos",
                "types": {
                    "classification": "Classificação",
                    "detection": "Detecção",
                    "segmentation": "Segmentação",
                    "language": "Linguagem",
                    "other": "Outros"
                }
            },
            "quantizations": "Quantizações",
            "toggles": {
                "inferenceNumber": "Mostrar número de inferências",
                "showPowerAndEnergy": "Mostrar potência e energia consumida",
                "orderByPowerAndEnergy": "Ordenar por potência e energia",
                "removeAll": "Remover todos",
                "selectAll": "Selecionar todos"
            },
            "buttons": {
                "apply": "Aplicar filtro"
            },
            "warnings": {
                "changesNotSaved": "Mudanças não salvas"
            }
        },
        "alert": {
            "label": "Alerta",
            "notSupported": "Modelos não suportados"
        },
        "table": {
            "inference": {
                "singular": "inferência",
                "plural": "inferências"
            },
            "unavailable": {
                "inferencesNumber": "Inferências não calculadas",
                "powerAndEnergy": "Consumo não calculado"
            }
        }
    },
    "llmRanking": {
        "title": "Ranking de LLMs",
        "description": "Esse ranking classifica smartphones Android pelos valores coletados no aplicativo Speed.AI LLM Version, que faz benchmarking de LLMs (Large Language Models, como Llama e Gemma) em aparelhos Android, usando a plataforma MLC LLM para a execução dos modelos.",
        "appCard": {
            "title": "Speed.AI - LLM Version",
            "description": "App usado para classificar os smartphones. Disponível no GitHub."
        },
        "filters": {
            "title": "Configurações do ranking",
            "subtitle": "Selecione modelos e quantizações que serão usados para calcular os resultados",
            "mode": {
                "total": "Tok/s (total)",
                "prefill": "Tok/s (prefill)",
                "decode": "Tok/s (decode)",
                "cpu": "Uso de CPU (%)",
                "gpu": "Uso de GPU (%)",
                "ram": "Uso de RAM (MB)"
            },
            "toggles": {
                "conversationNumber": "Mostrar número de conversas do dispositivo",
                "showPowerAndEnergy": "Mostrar potência e energia consumida",
                "orderByPowerAndEnergy": "Ordenar por potência e energia"
            },
            "models": {
                "label": "Modelos"
            }
        },
        "help": {
            "label": "Ajuda",
            "content": [
                {
                    "value": "prefill",
                    "label": "O que é prefill?",
                    "content": "Prefill tok/s mede quantos tokens o modelo pode processar por segundo durante a fase inicial de configuração."
                },
                {
                    "value": "decode",
                    "label": "O que é decode?",
                    "content": "Decode tok/s mede quantos tokens o modelo pode gerar por segundo durante a fase de decodificação."
                },
                {
                    "value": "conversation",
                    "label": "O que é uma conversa?",
                    "content": "Uma conversa é a etapa principal na avaliação de desempenho, durante a qual um conjunto predefinido de perguntas é feito ao modelo LLM. Durante esse processo, medimos os dados usados para construir a classificação."
                },
                {
                    "value": "result",
                    "label": "Como os tokens por segundo são calculados?",
                    "content": "Os tokens por segundo são calculados por meio de uma média simples de todas as conversas."
                },
                {
                    "value": "gpu",
                    "label": "Por que o consumo de GPU não está aparecendo?",
                    "content": "Alguns modelos de celulares não possibilitam a coleta da estatística do uso da GPU, por esse motivo alguns valores dessa medida podem estar ausentes."
                }
            ]
        },
        "phoneAlert": "É possivel que os nomes dos smartphones no ranking não sejam seus nomes comerciais",     
        "table": {
            "columns": {
                "result": {
                    "header": "Resultado"
                }
            },
            "conversation": {
                "singular": "conversa",
                "plural": "conversas"
            },
            "unavailable": {
                "conversatiosnNumber": "Nº de conversas não calculado",
                "powerAndEnergy": "Consumo não calculado"
            }
        }
    },
    "about": {
        "aboutLuxAI": {
            "title": "Sobre a Lux.AI",
            "content": "Lux.AI é um projeto desenvolvido no Centro de Informática da UFPE, como parte do PPI (Programas e Projetos Prioritários da Lei de Informática), com apoio do Ministério da Ciência, Tecnologia, Inovações e Comunicações, por meio da Lei de Informática (Lei Nº 8.248/91) e do Programa SOFTEX.\n\nAs principais áreas de estudo e desenvolvimento da Lux.AI incluem:\n\n1. Fotografia Computacional\n2. Inteligência Artificial\n3. Análise de Qualidade de Imagem\n4. Análise de Desempenho de Sistemas Heterogêneos.\n\nA Lux.AI desenvolve aplicativos móveis com funcionalidades baseadas em IA e aplica técnicas como treinamento, fine-tuning, pruning e outros métodos de otimização de desempenho para modelos de IA.\n\nAlém disso, oferece consultoria e serviços personalizados para a indústria, abrangendo desde o treinamento e fine-tuning de modelos de IA até a melhoria de desempenho em hardware restritivo."
        }
    }
}